"""Anthropic Claude provider for LLM functionality."""

import logging
from typing import Optional, Dict, Any

try:
    from anthropic import AsyncAnthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

from .base import LLMProvider, LLMResponse, LLMError


logger = logging.getLogger(__name__)


class ClaudeProvider(LLMProvider):
    """Anthropic Claude LLM provider."""
    
    def __init__(self, config: Dict[str, Any]):
        """Initialize Claude provider."""
        super().__init__(config)
        
        if not ANTHROPIC_AVAILABLE:
            raise LLMError(
                "anthropic package not available. Install with: pip install anthropic",
                "claude"
            )
        
        # Configure API key
        api_key = config.get("api_key")
        if not api_key:
            raise LLMError("Claude API key not provided in configuration", "claude")
        
        self.client = AsyncAnthropic(api_key=api_key)
        
        # Set up model configuration
        self.model_name = config.get("model", "claude-3-5-haiku-20241022")
        self.default_max_tokens = config.get("max_tokens", 2048)
        self.default_temperature = config.get("temperature", 0.7)
        
        logger.info(f"Initialized Claude provider with model: {self.model_name}")
    
    async def generate(
        self, 
        prompt: str, 
        system_prompt: Optional[str] = None,
        max_tokens: Optional[int] = None,
        temperature: Optional[float] = None,
        **kwargs
    ) -> LLMResponse:
        """Generate text using Claude."""
        try:
            # Prepare messages
            messages = [{"role": "user", "content": prompt}]
            
            # Set up generation parameters
            params = {
                "model": self.model_name,
                "max_tokens": max_tokens or self.default_max_tokens,
                "temperature": temperature or self.default_temperature,
                "messages": messages
            }
            
            # Add system prompt if provided
            if system_prompt:
                params["system"] = system_prompt
            else:
                params["system"] = self.get_default_system_prompt()
            
            # Add additional parameters
            if "top_p" in kwargs:
                params["top_p"] = kwargs["top_p"]
            if "top_k" in kwargs:
                params["top_k"] = kwargs["top_k"]
            
            # Generate response
            response = await self.client.messages.create(**params)
            
            if not response.content or not response.content[0].text:
                raise LLMError("No text generated by Claude", "claude")
            
            # Extract usage info
            usage = {}
            if hasattr(response, 'usage') and response.usage:
                usage = {
                    "prompt_tokens": response.usage.input_tokens,
                    "completion_tokens": response.usage.output_tokens,
                    "total_tokens": response.usage.input_tokens + response.usage.output_tokens
                }
            
            return LLMResponse(
                text=response.content[0].text,
                model=self.model_name,
                provider="claude",
                usage=usage,
                metadata={
                    "stop_reason": response.stop_reason,
                    "stop_sequence": response.stop_sequence,
                    "model": response.model,
                    "role": response.role
                }
            )
            
        except Exception as e:
            if isinstance(e, LLMError):
                raise
            
            logger.error(f"Claude generation error: {e}")
            raise LLMError(f"Claude generation failed: {str(e)}", "claude", e)
    
    async def health_check(self) -> bool:
        """Check if Claude is accessible."""
        try:
            # Try a simple generation to test connectivity
            response = await self.client.messages.create(
                model=self.model_name,
                max_tokens=10,
                messages=[{"role": "user", "content": "Hello"}]
            )
            return bool(response.content and response.content[0].text)
        except Exception as e:
            logger.warning(f"Claude health check failed: {e}")
            return False
    
    def get_available_models(self) -> list[str]:
        """Get list of available Claude models."""
        # As of current API, these are the main Claude models
        return [
            "claude-3-5-sonnet-20241022",
            "claude-3-5-haiku-20241022", 
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229",
            "claude-3-haiku-20240307"
        ]